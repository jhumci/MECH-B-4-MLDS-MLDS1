# Stichproben und Zufallsvariablen {#sec-statistics-sampling}

In diesem Abschnitt {#sec-statistics-sampling} behandeln wir Stichproben und Zufallsvariablen.

Eine Stichprobe umfasst $n$ Beobachtungen aus einer Grundgesamtheit, der Menge $N$ aller möglichen Beobachtungen. Sie ist eine Teilmenge der Grundgesamtheit und sollte idealerweise Rückschlüsse auf diese ermöglichen.

## Stichprobenziehung aus einer Grundgesamtheit {#sec-sampling-population}

Die Grundgesamtheit (_population_) ist die Gesamtheit aller untersuchbaren Beobachtungen, die Stichprobe (_sample_) eine Teilmenge davon. Eine repräsentative Stichprobe erlaubt Verallgemeinerungen. Da die vollständige Datenerhebung der Grundgesamtheit oft zu aufwendig und kostspielig ist, ziehen wir Rückschlüsse aus Stichproben (siehe Figure \@ref(fig:fig-sampling-population)). Dies gelingt am besten mit einer großen, zufällig ausgewählten Stichprobe.

```{python}
#| echo: false
#| label: fig-sampling-population
#| fig-cap: "Visualisierung der Stichprobenziehung aus einer Grundgesamtheit."
import plotly.graph_objects as go
import numpy as np

# Grundgesamtheit erzeugen
np.random.seed(42)
angles = np.random.uniform(0, 2 * np.pi, 200)
radii = np.random.uniform(0, 0.9, 200)
x_population = 1 + radii * np.cos(angles)
y_population = 1 + radii * np.sin(angles)

# Stichprobe ziehen (5 zufällige Punkte)
sample_indices = np.random.choice(len(x_population), 5, replace=False)
x_sample = x_population[sample_indices]
y_sample = y_population[sample_indices]

# Kreise für Grundgesamtheit und Stichprobe
circle1 = go.Scatter(
    x=1 + 0.9 * np.cos(np.linspace(0, 2*np.pi, 100)),
    y=1 + 0.9 * np.sin(np.linspace(0, 2*np.pi, 100)),
    mode="lines",
    line=dict(color="black"),
    showlegend=False
)

circle2 = go.Scatter(
    x=3 + 0.4 * np.cos(np.linspace(0, 2*np.pi, 100)),
    y=1 + 0.4 * np.sin(np.linspace(0, 2*np.pi, 100)),
    mode="lines",
    line=dict(color="black"),
    showlegend=False
)

# Punkte der Grundgesamtheit (blau)
population_points = go.Scatter(
    x=x_population, y=y_population,
    mode="markers", marker=dict(color="blue", opacity=0.5, size=4),
    name="Grundgesamtheit",
    text=["gut in Mathe" if i % 2 == 0 else "schlecht in Mathe" for i in range(len(x_population))],
    hoverinfo="text"
)

# Stichprobenpunkte (rot)
sample_points = go.Scatter(
    x=x_sample + 2, y=y_sample,
    mode="markers", marker=dict(color="red", size=8),
    name="Stichprobe",
    text=["gut in Mathe" if i % 2 == 0 else "schlecht in Mathe" for i in range(len(x_sample))],
    hoverinfo="text"
)

# Pfeile zwischen Grundgesamtheit und Stichprobe
arrows = [go.Scatter(
    x=[x_sample[i], x_sample[i] + 2],
    y=[y_sample[i], y_sample[i]],
    mode="lines",
    line=dict(color="black", width=2),
    showlegend=False
) for i in range(len(x_sample))]

# Beschriftungen
text_labels = go.Scatter(
    x=[0.2, 3.2], y=[1.8, 1.8],
    text=["Grundgesamtheit", "Stichprobe"],
    mode="text",
    textposition="top center",
    showlegend=False
)

# Layout
layout = go.Layout(
    xaxis=dict(visible=False),
    yaxis=dict(visible=False),
    showlegend=True,
    width=700,
    height=400
)

# Plot erstellen
fig = go.Figure(data=[circle1, circle2, population_points, sample_points, text_labels] + arrows, layout=layout)
fig.show()
```


Allerdings kommt es hier zu einen Unterschied zwischen der Sichtweise der _klassischen Statistik_ und dem Ansatz den den viele _Data Scientists_ verfolgen. 
In der klassischen Statistik wird die Stichprobe so gewählt, dass sie repräsentativ für die Grundgesamtheit ist.

:::::: {.callout-note}
Wenn wir die Leistungsfähigkeit in Mathematik unter Studierenden auswerten wollen, dann sollten wir unsere Stichprobe nicht nur im Studiengang Mechatronik nachfragen.
:::

Als _Data Scientist_ hingegen, sind wir oft an den Daten interessiert, die uns zur Verfügung stehen. Wir haben keine Möglichkeit, die Grundgesamtheit zu beeinflussen. 
Wir müssen also mit den Daten arbeiten, die wir haben und uns dabei bewusst sein, dass wir einem _Sampling-Bias_ unterliegen.

:::::: {.callout-note}
Wenn wir die die Lebensdauer eines Werkzeugs auf einer 5-Achs-Fräsmaschinene prognostizieren wollen, können wir die Modelle nicht zwischen Betrieben vergleichen, die die Maschine regelmäßig warten und solchen, die das nicht tun.
:::



## Unterschied zwischen klassischer Statistik und Data Science {#sec-classical-vs-datascience}

Die _klassische Statistik_ wählt Stichproben so, dass sie die Grundgesamtheit repräsentieren, während _Data Scientists_ oft mit verfügbaren Daten arbeiten und keinen Einfluss auf die Grundgesamtheit haben. Dies führt zu einem möglichen _Sampling-Bias_.

:::::: {.callout-note}
Zur Bewertung der Mathematikleistung von Studierenden wäre eine Stichprobe nur aus Mechatronik nicht repräsentativ.
::::::

:::::: {.callout-note}
Bei der Prognose der Werkzeuglebensdauer einer 5-Achs-Fräsmaschine sind Vergleiche zwischen gewarteten und ungewarteten Maschinen verzerrt.
::::::

## Gruppieren von Daten {#sec-grouping-data}

Ein bewusster Bias kann bei der Datenauswahl entstehen. Fragen wir z. B. nur Personen mit Hypothek (`mortgage`) nach ihrem Einkommen und nicht Mieter (`rent`), ist die Stichprobe nicht repräsentativ (siehe Figure \@ref(fig:fig-income-distribution)).

```{python}
#| classes: styled-output
#| label: fig-income-distribution
#| fig-cap: "Verteilung des jährlichen Einkommens nach Wohneigentum."
import pandas as pd
import seaborn as sns

df = pd.read_csv("../_assets/dataexploratory/loan50.csv")
sns.histplot(data=df, x="annual_income", bins=30, hue="homeownership")
```

```{python}
#| classes: styled-output
df.groupby("homeownership")["annual_income"].mean()
```

## Analyse der Daten {#sec-data-analysis}

:::::: {.callout-note}
Inwiefern entsprechen die Daten den Erwartungen?
::::::

Im Beispiel haben wir eine ordinal skalierte Variable (`homeownership`) und eine metrisch skalierte Variable (`annual_income`). Wir untersuchen ihren Zusammenhang. Korrelation und Kausalität, wie in der letzten Einheit besprochen, sind hier nicht anwendbar, da `homeownership` ordinal ist.

### Boxplot {#sec-boxplot}

Ein Boxplot eignet sich zum Vergleich ordinaler und metrischer Variablen. Er zeigt die Verteilung der metrischen Variable (`annual_income`) für die Ausprägungen der ordinalen Variable (`homeownership`). Die Box umfasst Median sowie erstes und drittes Quartil, die Whisker die Datenreichweite (1,5-fache Interquartilsdistanz ab den Quartilen), und Punkte markieren Ausreißer (siehe Figure \@ref(fig:fig-boxplot-income)).

```{python}
#| classes: styled-output
#| label: fig-boxplot-income
#| fig-cap: "Boxplot des jährlichen Einkommens nach Wohneigentum."
import pandas as pd
import seaborn as sns

df = pd.read_csv("../_assets/dataexploratory/loan50.csv")
sns.boxplot(data=df, x="homeownership", y="annual_income")
sns.stripplot(data=df, x="homeownership", y="annual_income", color="black", size=3, alpha=0.5)
```


Der Boxplot ist einfach zu erstellen und zu interpretieren, jedoch bei stark unterschiedlichen Verteilungen wenig aussagekräftig. Hier können Daten transformationen oder alternative Visualisierungen helfen.

:::::: {.callout-tip}
Eine moderne Alternative zum Boxplot ist der Violinplot. Er zeigt die Verteilung als geschätzte Wahrscheinlichkeitsdichte (bisher für uns ein geglättetes Histogramm) und ist informativer, da er die Datenverteilung detaillierter darstellt (siehe Figure \@ref(fig:fig-violin-plot)).
![xkcd Violinplot](https://imgs.xkcd.com/comics/violin_plots_2x.png){#fig-violin-plot}
::::::

### Experimente {#sec-experiments}

In der Statistik unterscheiden wir _Beobachtungsstudien_, bei denen Daten ohne Eingriff beobachtet werden, von _Experimenten_, bei denen Daten manipuliert werden, um Effekte zu prüfen. Experimente sind aufwendiger und teurer, ermöglichen aber die Untersuchung von Kausalzusammenhängen.

:::::: {.callout-note}
Beobachtungsstudien können longitudinal sein, z. B. die [Mathematikleistung von Studierenden über die Zeit](https://media.licdn.com/dms/image/v2/C4E12AQELtqr71MWseQ/article-cover_image-shrink_720_1280/article-cover_image-shrink_720_1280/0/1618928075307?e=1743638400&v=beta&t=rCguWezdBwq7diYbJUz-XXecyGSKu4_pTm_j1fD2mEE), oder Querschnittsstudien, z. B. die Leistung nach Studiengängen zu einem Zeitpunkt.
::::::

:::::: {.callout-note}
Um die Wirkung von Studiengängen auf die Mathematikleistung zu prüfen, könnten wir ein Experiment durchführen: Studierende zufällig Studiengängen zuweisen und ihre Leistung messen. Dies erfordert Zufallsauswahl und -zuweisung (ethische Bedenken beachten). Eine Kontrollgruppe ohne Studiengang schließt externe Einflüsse (z. B. Alter) aus. Eine Messung vor dem Studium ist bei zufälliger Zuweisung entbehrlich.
::::::

Experimente sind der Goldstandard für Kausalität. Eine unabhängige Variable (z. B. Studiengang) wird manipuliert, andere Variablen konstant gehalten oder durch große Stichproben ausgeglichen. Findet sich eine Korrelation zur abhängigen Variable (z. B. Mathematikleistung), ist Kausalität plausibel. Im Data Science wird oft pragmatisch mit vorhandenen Daten gearbeitet – schneller, aber weniger zuverlässig.

#### Beispiel: Ist ein Würfel gezinkt? {#sec-dice-example}

Stellen wir uns vor, eine Kollegin besteht auf ihrem eigenen Würfel. Ist er gezinkt? Eine Beobachtungsstudie könnte die Augenzahlen mit einem fairen Würfel (Kontrollgruppe) vergleichen. Wir werfen beide Würfel 1000-mal und prüfen die Verteilung (siehe Figure \@ref(fig:fig-dice-rolls-manipulated)). Auffällige Abweichungen machen misstrauisch.

```{python}
#| classes: styled-output
#| label: fig-dice-rolls-manipulated
#| fig-cap: "Verteilung der Würfelergebnisse: fairer vs. manipulierter Würfel."
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

np.random.seed(42)
fair_dice_rolls = np.random.randint(1, 7, 1000)
manipulated_dice_rolls = np.random.choice([1, 2, 3, 4, 5, 6], 1000, p=[1.9/12, 1.9/12, 1.9/12, 1.9/12, 1.9/12, 2.5/12])

sns.histplot(fair_dice_rolls, bins=6, discrete=True, color="lightblue", alpha=0.2, label="Fairer Würfel")
sns.histplot(manipulated_dice_rolls, bins=6, discrete=True, color="red", alpha=0.2, label="Manipulierter Würfel")
plt.legend()
```



## Blickpunkte auf Variablen {#sec-variable-perspectives}

Wir haben Variablen (Spalten in _tidy data_) untersucht und betrachten sie aus verschiedenen Perspektiven.

### Skalenniveaus {#sec-scale-levels}

Skalenniveaus klassifizieren Variablen in nominal, ordinal, metrisch und verhältnisskaliert. Sie bestimmen, welche statistischen Methoden zur Analyse geeignet sind.

### Im Kontext von Experimenten {#sec-experiment-context}

In Experimenten und Beobachtungsstudien unterscheiden wir _unabhängige_ (Einflussgröße) und _abhängige_ (gemessene Effekte) Variablen. Bezeichnungen variieren je nach Fachgebiet (siehe Table \@ref(tab:tab-variable-terms)). Später erkennen wir, dass mehrere unabhängige und abhängige Variablen möglich sind, doch zunächst bleiben wir bei Singular.

| Anwendungsfeld   | Unabhängige Variable | Abhängige Variable |
|------------------|----------------------|--------------------|
| Statistik        | Explanatory Variable | Response Variable  |
| Machine Learning | Features             | Target             |
| Experimente      | Treatment            | Outcome            |
| Psychologie      | Independent Variable | Dependent Variable |
| Forecasts        | Predictor            | Predicted Variable |
| Ökonometrie      | Explanatory Variable | Dependent Variable |
| Informatik       | Input                | Output             |
| Programming      | Argument             | Return Value       |
| Programming      | `X`                  | `y`                |

## Wahrscheinlichkeitsrechnung {#sec-probability}

Eine weitere Perspektive sind Prozesse hinter Beobachtungen: _deterministisch_ (gleiches Ergebnis bei gleichen Bedingungen) oder _zufällig_ (unterschiedliche Ergebnisse trotz gleicher Bedingungen). Zufällige Prozesse werden durch Wahrscheinlichkeiten beschrieben.

:::::: {.callout-important}
Ob das Universum deterministisch oder zufällig ist, spielt keine Rolle. Zufälligkeit bedeutet hier, dass Ergebnisse nicht a priori vorhersagbar sind – sei es durch echte Zufallsprozesse (z. B. Würfeln) oder unvollständige Modellierung (z. B. fehlende Variablen).
::::::

### Zufallsvariablen {#sec-random-variables}

Eine Zufallsvariable nimmt zufällig Werte an – diskret (bestimmte Werte, z. B. Würfelaugenzahl: 1–6) oder kontinuierlich (Werte in einem Intervall, z. B. Temperatur). Die Augenzahl eines Würfels ist eine diskrete Zufallsvariable; jeder Wurf ist eine Realisierung (siehe Figure \@ref(fig:fig-dice-rolls)).

```{python}
#| classes: styled-output
#| label: fig-dice-rolls
#| fig-cap: "Verteilung der Würfelergebnisse bei 1000 Würfen."
import numpy as np
import seaborn as sns

np.random.seed(42)
dice_rolls = np.random.randint(1, 7, 1000)
sns.histplot(dice_rolls, bins=6, discrete=True)
```


## Zufallsvariablen und Münzwurf {#sec-random-variables-coin}

Ähnlich wie beim Würfel ist beim Münzwurf die Zufallsvariable die Seite, die oben liegt (Kopf oder Zahl). Für numerische Analysen wandeln wir diese kategorialen Werte in 0 (Zahl) und 1 (Kopf) um, wodurch der Ereignisraum {Kopf, Zahl} zu {0, 1} wird.

### Begriffe der Wahrscheinlichkeit {#sec-probability-terms}

Wir definieren:
- __Zufallsexperiment/-prozess__: Ein Prozess mit unvorhersagbarem Ergebnis, z. B. Münzwurf, Würfeln oder Kartenziehen.
- __Ereignisraum__ (_sample space_): Alle möglichen Ergebnisse eines Zufallsexperiments, z. B. {Kopf, Zahl} beim Münzwurf.
- __Zufallsvariable__: Eine Funktion, die jedem Ergebnis eine Zahl zuordnet, z. B. 1 für Kopf und 0 für Zahl.

## Frequentistische Wahrscheinlichkeit {#sec-frequentist-probability}

:::::: {.callout-important}
Die __Wahrscheinlichkeit__ eines Ergebnisses ist der Anteil, wie oft es bei unendlich vielen Wiederholungen eines Zufallsprozesses eintritt. Sie liegt zwischen 0 und 1 und kann als Prozentsatz (0–100 %) angegeben werden.
::::::

In Figure \@ref(fig:fig-dice-rolls) trat die Augenzahl 2 etwa 167-mal in 1000 Würfen auf, was einer Wahrscheinlichkeit von ca. 1/6 (0,167) entspricht – ebenso für die anderen Augenzahlen. Bei endlichen Beobachtungen ist dies eine Schätzung; die exakte Wahrscheinlichkeit gilt nur für unendlich viele Versuche (siehe Figure \@ref(fig:fig-dice-rolls-proportion)).

```{python}
#| classes: styled-output
#| label: fig-dice-rolls-proportion
#| fig-cap: "Anteil der Würfelergebnisse '1' über die Anzahl der Würfe."
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

number_of_rolls = 1000
np.random.seed(10)
dice_rolls = np.random.randint(1, 7, number_of_rolls)

proportion_ones = np.cumsum(dice_rolls == 1) / np.arange(1, number_of_rolls + 1)

sns.lineplot(x=np.arange(1, number_of_rolls + 1), y=proportion_ones)
sns.lineplot(x=[1, number_of_rolls + 1], y=[1/6, 1/6], color="red", linestyle="--")
plt.xlabel("$n$ - Anzahl der Würfe")
plt.ylabel("$\hat{p}_n$ - Anteil der 1en")
```

### Konvergenz und Schätzungen {#sec-convergence-estimates}

Figure \@ref(fig:fig-dice-rolls-proportion) zeigt den Anteil $\hat{p}_n$ der Augenzahl 1 bei jedem Schritt $n$ einer Simulation. Er konvergiert gegen die Wahrscheinlichkeit 1/6 (ca. 0,167). Der beobachtete Anteil $\hat{p}_n$ schätzt die Wahrscheinlichkeit $p$ und wird mit mehr Beobachtungen genauer; $p$ ist der Grenzwert.

:::::: {.callout-important}
In der Statistik arbeiten wir oft mit Schätzungen, da unendlich viele Beobachtungen fehlen. Die Unsicherheit der Schätzungen muss berücksichtigt werden. Schätzungen kennzeichnen wir mit $\hat{p}$.
::::::

:::::: {.callout-important}
__Gesetz der großen Zahlen__: Mit steigender Beobachtungszahl konvergiert der Anteil eines Ergebnisses gegen dessen Wahrscheinlichkeit.
::::::

### Wahrscheinlichkeitsnotation {#sec-probability-notation}

Für verschiedene Ergebnisse schreiben wir $P(X = x)$ als Wahrscheinlichkeit, dass die Zufallsvariable $X$ (z. B. Münzwurf) den Wert $x$ annimmt.  
- Für einen fairen Münzwurf:  
  $P(X = \text{Kopf}) = 0.5$, $P(X = \text{Zahl}) = 0.5$  
  oder: $P(X = 1) = 0.5$, $P(X = 0) = 0.5$.  
- Für einen fairen Würfelwurf:  
  $P(X = 1) = P(X = 2) = P(X = 3) = P(X = 4) = P(X = 5) = P(X = 6) = 1/6$.

Die Summe der Wahrscheinlichkeiten aller Ergebnisse eines Zufallsexperiments ist stets 1, da mindestens ein Ergebnis eintritt. Dies entspricht der Fläche unter einem normalisierten Histogramm oder einer Dichtefunktion.

### Disjunkte Ereignisse {#sec-disjoint-events}

Zwei Ereignisse $A$ und $B$ sind __disjunkt__ (sich ausschließend), wenn sie nicht gleichzeitig eintreten können. Beispiel: Bei einem Würfelwurf sind „Augenzahl 1“ und „Augenzahl 2“ disjunkt. Die Wahrscheinlichkeit, dass eines von beiden eintritt, ist $P(A \cup B)$ (logisches „oder“, „A vereinigt B“):  
$$P(X=1 \cup X=2) = P(X=1) + P(X=2) = \frac{1}{6} + \frac{1}{6} = \frac{1}{3}.$$

:::::: {.callout-important}
__Additionsregel__: Für sich ausschließende Ereignisse $A$ und $B$ gilt:  
$$P(A \cup B) = P(A) + P(B).$$  
Für mehrere disjunkte Ereignisse $A_1, \ldots, A_n$:  
$$P(A_1 \cup A_2 \cup \ldots \cup A_n) = P(A_1) + P(A_2) + \ldots + P(A_n).$$
::::::
#### Beispiel: Kreditnehmer-Datensatz {#sec-loan-example}

Im Datensatz aus Kapitel 2 beschreibt `homeownership`, ob ein Kreditnehmer mietet, eine Hypothek hat oder Eigentümer ist. Von 50 Kreditnehmern (siehe Code-Ausgabe) sind die Verteilungen: Miete (21), Hypothek (26), Eigentum (3).

```{python}
#| classes: styled-output
#| label: tab-loan-homeownership
#| tbl-cap: "Verteilung der Wohneigentumsarten im Kreditnehmer-Datensatz."
import pandas as pd

df = pd.read_csv("../_assets/dataexploratory/loan50.csv")
print(f"Anzahl Beobachtungen: {df['homeownership'].shape[0]}")
print(df["homeownership"].value_counts())
```

1. Sind Miete, Hypothek und Eigentum disjunkt?
2. Bestimmen Sie den Anteil der Kredite mit Hypothek und Eigentum separat.
3. Nutzen Sie die Additionsregel für disjunkte Ereignisse, um die Wahrscheinlichkeit zu berechnen, dass ein zufällig ausgewählter Kreditnehmer eine Hypothek hat oder Eigentümer ist.

:::::: {.callout-tip collapse="true"}

1. Ja, die Kategorien sind disjunkt, da ein Kreditnehmer nur eine davon haben kann.
2. Anteil Hypothek: $\frac{26}{50}$, Anteil Eigentum: $\frac{3}{50}$.
3. Wahrscheinlichkeit (Hypothek oder Eigentum): $\frac{26}{50} + \frac{3}{50} = \frac{29}{50}$. Dies entspricht der Wahrscheinlichkeit, nicht zu mieten. ::::::

::::::

### Das Komplement eines Ereignisses {#sec-complement}

Das Komplement eines Ereignisses $A$, bezeichnet als $A^c$ oder $\bar{A}$, ist das Nicht-Eintreten von $A$. Es umfasst alle Ergebnisse außer $A$ und ist zu $A$ disjunkt. Die Wahrscheinlichkeit des Komplements ist:

$$
P(A^c) = 1 - P(A)
$$

Beispiel: Die Wahrscheinlichkeit, dass ein Würfel nicht 1 zeigt:


$$
1 - P(X \neq 1) =1-P(X=1) = 1 - \frac{1}{6} = \frac{5}{6}.
$$

Die Summe $P(A) + P(A^c) = 1$ gilt stets, da entweder $A$ oder $A^c$ eintritt.

### Nicht-disjunkte Ereignisse {#sec-non-disjoint-events}

Nicht-disjunkte Ereignisse können überlappen. Beispiel: Bei einem Kartenspiel (siehe Figure @ref(fig:fig-card-deck)) interessiert die Wahrscheinlichkeit, eine Bildkarte (Bube, Dame, König) oder eine Karo-Karte zu ziehen. *Bild* und *Karo* sind nicht disjunkt, da Bildkarten in Karo beide Eigenschaften haben. Einfaches Addieren überschätzt die Wahrscheinlichkeit durch doppelte Zählung.

![Deck of 52 Cards](../_assets/dataexploratory/card_deck.png){#fig-card-deck}


Ein Venn-Diagramm (siehe Figure @ref(fig:fig-card-venn)) zeigt: Die Schnittmenge ($A \cap B$, logisches „und“) sind Karten, die beide Eigenschaften haben; die Vereinigung ($A \cup B$, logisches „oder“) umfasst alle Karten mit mindestens einer Eigenschaft.

![Venn Diagramm of Cards](../_assets/dataexploratory/card_venn.png){#fig-card-venn}

Von 52 Karten sind 12 Bildkarten, 13 Karo-Karten und 3 sowohl Bild- als auch Karo-Karten. Die Wahrscheinlichkeit für „Bild oder Karo“ ist:

$$
P(\text{Bild} \cup \text{Karo}) = P(\text{Bild}) + P(\text{Karo}) - P(\text{Bild} \cap \text{Karo}).
= \frac{12}{52} + \frac{13}{52} - \frac{3}{52} = \frac{22}{52}.
$$


Hierraus können wir die __Additionsregel__ für nicht-disjunkte Ereignisse formulieren:

:::::: {.callout-important}
Generelle Additionsregel: Für nicht-disjunkte Ereignisse $A$ und $B$ gilt:

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B).
$$
::::::


#### Beispiel: Summe zweier Würfel {#sec-dice-sum-example}

Sei $A$ das Ereignis, dass die Summe der Augenzahlen zweier fairer Würfel kleiner als 12 ist.

1. Was ist das Komplement von $A$?
2. Wie groß ist $P(A)$?

:::::: {.callout-tip collapse="true"}
1. Das Komplement $A^c$ ist die Summe $\geq 12$, also genau 12 (da die maximale Summe 12 beträgt).
2. $P(A)$ ist die Summe der Wahrscheinlichkeiten für Summen 2 bis 11.  
   Mögliche Summen und Kombinationen (siehe Table \@ref(tab:tab-dice-sums)):  

| $A = W_1 + W_2$ | Mögliche Kombinationen |
|-----------------|-----------------------|
| 2               | $(W_1=1 \cap W_2=1)$ |
| 3               | $(W_1=1 \cap W_2=2) \cup (W_1=2 \cap W_2=1)$ |
| 4               | $(W_1=1 \cap W_2=3) \cup (W_1=2 \cap W_2=2) \cup (W_1=3 \cap W_2=1)$ |
| 5               | $(W_1=1 \cap W_2=4) \cup (W_1=2 \cap W_2=3) \cup (W_1=3 \cap W_2=2) \cup (W_1=4 \cap W_2=1)$ |
| 6               | $(W_1=1 \cap W_2=5) \cup (W_1=2 \cap W_2=4) \cup (W_1=3 \cap W_2=3) \cup (W_1=4 \cap W_2=2) \cup (W_1=5 \cap W_2=1)$ |
| 7               | $(W_1=1 \cap W_2=6) \cup (W_1=2 \cap W_2=5) \cup (W_1=3 \cap W_2=4) \cup (W_1=4 \cap W_2=3) \cup (W_1=5 \cap W_2=2) \cup (W_1=6 \cap W_2=1)$ |
| 8               | $(W_1=2 \cap W_2=6) \cup (W_1=3 \cap W_2=5) \cup (W_1=4 \cap W_2=4) \cup (W_1=5 \cap W_2=3) \cup (W_1=6 \cap W_2=2)$ |
| 9               | $(W_1=3 \cap W_2=6) \cup (W_1=4 \cap W_2=5) \cup (W_1=5 \cap W_2=4) \cup (W_1=6 \cap W_2=3)$ |
| 10              | $(W_1=4 \cap W_2=6) \cup (W_1=5 \cap W_2=5) \cup (W_1=6 \cap W_2=4)$ |
| 11              | $(W_1=5 \cap W_2=6) \cup (W_1=6 \cap W_2=5)$ |
| 12              | $(W_1=6 \cap W_2=6)$ |

Die Gesamtzahl der Kombinationen beträgt $6 \times 6 = 36$. Für $A^c$ (Summe = 12) gibt es 1 Fall, also $P(A^c) = \frac{1}{36}$ und $P(A) = 1 - P(A^c) = \frac{35}{36}$.
::::::

Bei komplexeren Berechnungen hilft eine __Monte-Carlo-Simulation__: Das Experiment wird mehrfach simuliert, und die Wahrscheinlichkeit ergibt sich aus dem Anteil der Treffer (siehe Code-Ausgabe).

```{python}
#| classes: styled-output
#| label: tab-dice-simulation
#| tbl-cap: "Monte-Carlo-Simulation der Wahrscheinlichkeit, dass die Summe zweier Würfel < 12 ist."
import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.randint(1, 7, (10000, 2)), columns=["W1", "W2"])
df["Sum"] = df["W1"] + df["W2"]
p = (df["Sum"] < 12).mean()

print(f"Die Wahrscheinlichkeit, dass die Summe < 12 ist, beträgt {p:.3f}")
```

#### Simulation der Würfelsumme (Fortsetzung) {#sec-dice-sum-simulation}

Die Verteilung der Summen zweier Würfel kann auch grafisch dargestellt werden (siehe Figure \@ref(fig:fig-dice-sum)). Die Simulation bestätigt, dass die Wahrscheinlichkeit für eine Summe < 12 hoch ist.

```{python}
#| classes: styled-output
#| label: fig-dice-sum
#| fig-cap: "Verteilung der Summen zweier Würfel bei 10.000 Würfen; rote Linie markiert Summe = 11."
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np

df = pd.DataFrame(np.random.randint(1, 7, (10000, 2)), columns=["W1", "W2"])
df["Sum"] = df["W1"] + df["W2"]

sns.histplot(df["Sum"], bins=11, discrete=True, stat='density')
plt.axvline(11, color="red", linestyle="--")
plt.xlabel("Summe der Augenzahlen")
plt.ylabel("Dichte")
plt.show()
```
### Wahrscheinlichkeit der Würfelsumme (Fortsetzung) {#sec-dice-sum-probability}

Figure \@ref(fig:fig-dice-sum) zeigt die Verteilung der Summen zweier Würfel. Die Wahrscheinlichkeit, dass die Summe < 12 ist, beträgt ca. 0,97 (Monte-Carlo-Schätzung).  
- 3. Die Wahrscheinlichkeit für eine Summe $\geq 12$ ist:  
  $$P(A^c) = 1 - P(A) = 1 - \frac{35}{36} = \frac{1}{36} \approx 0.03.$$

## Unabhängige Ereignisse {#sec-independent-events}

Zwei Ereignisse $A$ und $B$ sind unabhängig, wenn das Eintreten des einen das andere nicht beeinflusst (vgl. Korrelation und Kausalität in @sec-dataexploratory-data_sets). Die Wahrscheinlichkeit eines Ereignisses hängt nicht vom anderen ab. Beispiele: Münzwurf und Würfelwurf oder die Ergebnisse zweier Würfel – das Ergebnis des ersten Würfels beeinflusst den zweiten nicht.

Die Wahrscheinlichkeit, dass zwei unabhängige Ereignisse gleichzeitig eintreten, ist:  
$$P(A \cap B) = P(A) \cdot P(B).$$

:::::: {.callout-important}
__Multiplikationsregel für unabhängige Ereignisse__: Für unabhängige Ereignisse $A$ und $B$ gilt:  
$$P(A \cap B) = P(A) \cdot P(B).$$  
Für mehrere unabhängige Ereignisse $A_1, \ldots, A_n$:  
$$P(A_1 \cap A_2 \cap \ldots \cap A_n) = P(A_1) \cdot P(A_2) \cdot \ldots \cdot P(A_n).$$
::::::

### Beispiel 1: Würfelsummen {#sec-dice-sum-example-1}

Da die Ergebnisse zweier Würfel unabhängig sind, können wir die Wahrscheinlichkeiten multiplizieren (siehe Table \@ref(tab:tab-dice-sum-probabilities)).  



| $A = W_1 + W_2$ | Mögliche Kombinationen         | $P(A)$                                                                 |
|-----------------|--------------------------------|------------------------------------------------------------------------|
| 2               | $W_1=1, W_2=1$                | $P(A=2) = P(W_1=1) \cdot P(W_2=1) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}$ |
| 3               | $W_1=1, W_2=2$, $W_1=2, W_2=1$ | $P(A=3) = P(W_1=1) \cdot P(W_2=2) + P(W_1=2) \cdot P(W_2=1) = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} = \frac{2}{36}$ |
| 4               | $W_1=1, W_2=3$, $W_1=2, W_2=2$, $W_1=3, W_2=1$ | $P(A=4) = P(W_1=1) \cdot P(W_2=3) + P(W_1=2) \cdot P(W_2=2) + P(W_1=3) \cdot P(W_2=1) = \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} + \frac{1}{6} \cdot \frac{1}{6} = \frac{3}{36}$ |
| 5               | $W_1=1, W_2=4$, $W_1=2, W_2=3$, $W_1=3, W_2=2$, $W_1=4, W_2=1$ | $P(A=5) = P(W_1=1) \cdot P(W_2=4) + P(W_1=2) \cdot P(W_2=3) + P(W_1=3) \cdot P(W_2=2) + P(W_1=4) \cdot P(W_2=1) =
\frac{4}{36}$ |
| 6               | $W_1=1, W_2=5$, $W_1=2, W_2=4$, $W_1=3, W_2=3$, $W_1=4, W_2=2$, $W_1=5, W_2=1$ | $P(A=6) = P(W_1=1) \cdot P(W_2=5) + P(W_1=2) \cdot P(W_2=4) + P(W_1=3) \cdot P(W_2=3) + P(W_1=4) \cdot P(W_2=2) + P(W_1=5) \cdot P(W_2=1) =
\frac{5}{36}$ |
| 7               | $W_1=1, W_2=6$, $W_1=2, W_2=5$, $W_1=3, W_2=4$, $W_1=4, W_2=3$, $W_1=5, W_2=2$, $W_1=6, W_2=1$ | $P(A=7) = P(W_1=1) \cdot P(W_2=6) + P(W_1=2) \cdot P(W_2=5) + P(W_1=3) \cdot P(W_2=4) + P(W_1=4) \cdot P(W_2=3) + P(W_1=5) \cdot P(W_2=2) + P(W_1=6) \cdot P(W_2=1) = \frac{6}{36}$ |
| 8               | $W_1=2, W_2=6$, $W_1=3, W_2=5$, $W_1=4, W_2=4$, $W_1=5, W_2=3$, $W_1=6, W_2=2$ | $P(A=8) = P(W_1=2) \cdot P(W_2=6) + P(W_1=3) \cdot P(W_2=5) + P(W_1=4) \cdot P(W_2=4) + P(W_1=5) \cdot P(W_2=3) + P(W_1=6) \cdot P(W_2=2) = \frac{5}{36}$ |
| 9               | $W_1=3, W_2=6$, $W_1=4, W_2=5$, $W_1=5, W_2=4$, $W_1=6, W_2=3$ | $P(A=9) = P(W_1=3) \cdot P(W_2=6) + P(W_1=4) \cdot P(W_2=5) + P(W_1=5) \cdot P(W_2=4) + P(W_1=6) \cdot P(W_2=3) = \frac{4}{36}$ |
| 10              | $W_1=4, W_2=6$, $W_1=5, W_2=5$, $W_1=6, W_2=4$ | $P(A=10) = P(W_1=4) \cdot P(W_2=6) + P(W_1=5) \cdot P(W_2=5) + P(W_1=6) \cdot P(W_2=4) = \frac{3}{36}$ |
| 11              | $W_1=5, W_2=6$, $W_1=6, W_2=5$ | $P(A=11) = P(W_1=5) \cdot P(W_2=6) + P(W_1=6) \cdot P(W_2=5) = \frac{2}{36}$ |
| 12              | $W_1=6, W_2=6$ | $P(A=12) = P(W_1=6) \cdot P(W_2=6) = \frac{1}{36}$ |


### Beispiel 2: Wahr oder Falsch {#sec-example-2-true-false}

Bestimmen Sie, ob die folgenden Aussagen wahr oder falsch sind, und begründen Sie Ihre Antwort.

1. Wenn eine faire Münze oft geworfen wird und die letzten acht Würfe Kopf waren, ist die Wahrscheinlichkeit, dass der nächste Wurf Kopf ist, etwas weniger als 50 %.
2. Das Ziehen einer Bildkarte (Bube, Dame, König) und das Ziehen einer roten Karte aus einem vollständigen Kartenspiel sind sich gegenseitig ausschließende Ereignisse.
3. Das Ziehen einer Bildkarte und das Ziehen eines Asses aus einem vollständigen Kartenspiel sind sich gegenseitig ausschließende Ereignisse.

:::::: {.callout-tip collapse="true"}
1. Falsch. Bei einer fairen Münze ist $P(\text{Kopf}) = 0.5$. Vorherige Würfe beeinflussen den nächsten nicht, da sie unabhängig sind.
2. Falsch. Bildkarten können rot sein (z. B. Karo-Dame). „Bildkarte“ und „rote Karte“ sind nicht disjunkt.
3. Wahr. Eine Bildkarte (Bube, Dame, König) kann kein Ass sein; die Ereignisse sind disjunkt.
::::::

### Bedingte Wahrscheinlichkeit {#sec-conditional-probability}

Bedingte Wahrscheinlichkeit beschreibt die Wahrscheinlichkeit eines Ereignisses $A$, gegeben dass ein anderes Ereignis $B$ eingetreten ist, notiert als $P(A | B)$ („$A$ gegeben $B$“). Beispiel: Wie wahrscheinlich ist eine Bildkarte, wenn die Karte eine Karo-Karte ist? Aus Figure \@ref(fig:fig-card-venn):  
$$P(\text{Bild} | \text{Karo}) = \frac{3}{13},$$  
da von 13 Karo-Karten 3 Bildkarten sind.

Eine Kreuztabelle (_contingency table_) zeigt die Häufigkeiten von Ereigniskombinationen, z. B. im `loan50`-Datensatz (siehe Table \@ref(tab:tab-contingency-loan)).

```{python}
#| classes: styled-output
#| label: tab-contingency-loan
#| tbl-cap: "Kreuztabelle von Wohneigentum und zweitem Einkommen im loan50-Datensatz."
import pandas as pd

df = pd.read_csv("../_assets/dataexploratory/loan50.csv")
contingency_table = pd.crosstab(df['homeownership'], df['has_second_income'])
print(contingency_table)
```
### Bedingte Wahrscheinlichkeit (Fortsetzung) {#sec-conditional-probability-cont}

Aus der Kreuztabelle (Table \@ref(tab:tab-contingency-loan)) ergibt sich: Von 26 Kreditnehmern mit Hypothek haben 6 ein zweites Einkommen. Die bedingte Wahrscheinlichkeit ist:  
$$P(\text{Zweiteinkommen} | \text{Hypothek}) = \frac{6}{26}.$$

:::::: {.callout-important}
Die __bedingte Wahrscheinlichkeit__ $P(A|B)$ ist die Wahrscheinlichkeit von $A$, gegeben dass $B$ eingetreten ist. Sie wird berechnet als:  
$$P(A|B) = \frac{P(A \cap B)}{P(B)}.$$  
Im Beispiel:  
$$P(\text{Zweiteinkommen} | \text{Hypothek}) = \frac{P(\text{Zweiteinkommen} \cap \text{Hypothek})}{P(\text{Hypothek})} = \frac{\frac{6}{50}}{\frac{26}{50}} = \frac{6}{26}.$$
::::::

:::::: {.callout-warning}
$P(A \cap B)$ kann hier nicht via Multiplikationsregel berechnet werden, da die Ereignisse nicht unabhängig sind. Stattdessen werden beobachtete Häufigkeiten verwendet.
::::::

:::::: {.callout-important}
__Summe bedingter Wahrscheinlichkeiten__: Sind $A_1, \ldots, A_k$ alle disjunkten Ergebnisse einer Variable, gilt für ein Ereignis $B$:  
$$P(A_1|B) + \cdots + P(A_k|B) = 1.$$  
Für ein Ereignis und sein Komplement:  
$$P(A|B) = 1 - P(A^c|B).$$
::::::




### Beispiel: AIDS-Test {#sec-aids-test-example}

![Meme AIDS Test](https://preview.redd.it/wait-how-does-this-math-work-v0-dh4j1hy9qu6e1.jpeg?auto=webp&s=7e663ac296036ba082fbe3091a82f9946323e025){#fig-meme-test-aids}

Wie hoch ist die Wahrscheinlichkeit, dass eine Person AIDS hat, wenn folgendes bekannt ist:
- Die Wahrscheinlichkeit, dass eine Person AIDS hat, beträgt 0,1 % ($P(\text{AIDS}) = 0.001$).
- Bei AIDS beträgt die Wahrscheinlichkeit eines positiven Tests 99 % ($P(\text{Positiv} | \text{AIDS}) = 0.99$, Sensitivität).
- Ohne AIDS beträgt die Wahrscheinlichkeit eines positiven Tests 5 % ($P(\text{Positiv} | \text{Kein AIDS}) = 0.05$, falsch-positiv, 1 - Spezifität).

:::::: {.callout-tip collapse="true"}
Ein Baumdiagramm hilft: $P(\text{AIDS}) = 0.001$, $P(\text{Kein AIDS}) = 0.999$, $P(\text{Positiv} | \text{AIDS}) = 0.99$, $P(\text{Positiv} | \text{Kein AIDS}) = 0.05$.


```{mermaid}
graph LR
    U[Person] -->|0.001| A[Krebs] 
    U[Person] -->|0.999| D[Kein Krebs]
    A[Krebs] -->|0.99| B[Positiv]
    A[Krebs] -->|0.01| C[Negativ]
    D[Kein Krebs] -->|0.05| E[Positiv]
    D[Kein Krebs] -->|0.95| F[Negativ]
```

Pfade mit positivem Test (disjunkt):

- Oberer Pfad: $P(\text{AIDS} \cap \text{Positiv}) = P(\text{AIDS}) \cdot P(\text{Positiv} | \text{AIDS}) = 0.001 \cdot 0.99 = 0.00099$.
- Unterer Pfad: $P(\text{Kein AIDS} \cap \text{Positiv}) = P(\text{Kein AIDS}) \cdot P(\text{Positiv} | \text{Kein AIDS}) = 0.999 \cdot 0.05 = 0.04995$.
- Gesamt: $P(\text{Positiv}) = 0.00099 + 0.04995 = 0.05094$.


Bedingte Wahrscheinlichkeit:

$$
P(\text{AIDS} | \text{Positiv}) = \frac{P(\text{AIDS} \cap \text{Positiv})}{P(\text{Positiv})} = \frac{0.00099}{0.05094} = 0.0194.
$$

Trotz positivem Test ist die Wahrscheinlichkeit für AIDS gering (ca. 1,94 %). In der Praxis folgen Bestätigungstests, und die Prävalenz in Risikogruppen ist höher als 0,1 %.
::::::

### Satz von Bayes {#sec-bayes-theorem}

Im AIDS-Test-Beispiel kennen wir $P(\text{Positiv} | \text{AIDS})$ – die Wahrscheinlichkeit eines positiven Tests bei AIDS – und möchten die Umkehrung, $P(\text{AIDS} | \text{Positiv})$ – die Wahrscheinlichkeit von AIDS bei einem positiven Test. Diese Umkehrung nennt sich _bedingte Wahrscheinlichkeit_ in umgekehrter Richtung. Doch wie gelangen wir von der einen zur anderen? Der Satz von Bayes liefert die Lösung, indem er bedingte Wahrscheinlichkeiten umkehrt.

#### Motivation und Herleitung

Stellen wir uns vor, wir wollen $P(\text{AIDS} | \text{Positiv})$ berechnen. Aus der Definition der bedingten Wahrscheinlichkeit wissen wir:  
$$P(\text{AIDS} | \text{Positiv}) = \frac{P(\text{AIDS} \cap \text{Positiv})}{P(\text{Positiv})}.$$  
Gleichzeitig gilt für die umgekehrte Richtung:  
$$P(\text{Positiv} | \text{AIDS}) = \frac{P(\text{Positiv} \cap \text{AIDS})}{P(\text{AIDS})}.$$  
Da $P(\text{AIDS} \cap \text{Positiv}) = P(\text{Positiv} \cap \text{AIDS})$ (Schnittmengen sind symmetrisch), können wir die zweite Gleichung umstellen:  
$$P(\text{AIDS} \cap \text{Positiv}) = P(\text{Positiv} | \text{AIDS}) \cdot P(\text{AIDS}).$$  
Setzen wir dies in die erste Gleichung ein:  
$$P(\text{AIDS} | \text{Positiv}) = \frac{P(\text{Positiv} | \text{AIDS}) \cdot P(\text{AIDS})}{P(\text{Positiv})}.$$  
Das ist der Satz von Bayes! Er verbindet die bekannte Bedingung ($P(\text{Positiv} | \text{AIDS})$) mit der gesuchten ($P(\text{AIDS} | \text{Positiv})$), wobei $P(\text{Positiv})$ die Gesamtwahrscheinlichkeit eines positiven Tests ist.

#### Formale Definition

Der Satz von Bayes lautet allgemein:  
$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)},$$  
wobei:  
- $P(A|B)$ die _Posterior_-Wahrscheinlichkeit ist (z. B. AIDS bei positivem Test),  
- $P(B|A)$ die _Likelihood_ (z. B. positiver Test bei AIDS),  
- $P(A)$ der _Prior_ (z. B. Grundwahrscheinlichkeit für AIDS),  
- $P(B)$ die _Normalisierungskonstante_ (z. B. Gesamtwahrscheinlichkeit eines positiven Tests).

#### Anwendung

Im AIDS-Beispiel:  
- $P(\text{Positiv} | \text{AIDS}) = 0.99$,  
- $P(\text{AIDS}) = 0.001$,  
- $P(\text{Positiv}) = P(\text{Positiv} | \text{AIDS}) \cdot P(\text{AIDS}) + P(\text{Positiv} | \text{Kein AIDS}) \cdot P(\text{Kein AIDS}) = 0.00099 + 0.04995 = 0.05094$.  
Damit:  
$$P(\text{AIDS} | \text{Positiv}) = \frac{0.99 \cdot 0.001}{0.05094} \approx 0.01943.$$  
Der Satz von Bayes ist in Medizin, Wirtschaft und Technik essenziell, um aus bekannten Daten (z. B. Testresultaten) auf Ursachen (z. B. Krankheiten) zu schließen.


::: {.callout-tip}
Youtube-Videos:

- [Three Blue One Brown: Bayes Theorem](https://www.youtube.com/watch?v=HZGCoVF3YvM)
- [Veritasium: The Bayesian Trap
](https://www.youtube.com/watch?v=R13BD8qKeTg)

:::


::: {.callout-tip}
### Assoziationsanalyse mit A-Priori-Algorithmus
Die [Assoziationsanalyse](https://de.wikipedia.org/wiki/Assoziationsanalyse) ist ein Verfahren, um Zusammenhänge in Daten zu finden. Ein bekannter Algorithmus ist der [A-Priori-Algorithmus](https://de.wikipedia.org/wiki/Apriori-Algorithmus), der z.B. in für Predictive Maintainance oder in der Warenkorbanalyse verwendet wird. Der A-Priori-Algorithmus findet heraus, welche Produkte oft zusammen gekauft werden. Ein Beispiel ist, dass Kunden, die Windeln kaufen, oft auch Bier kaufen.
:::

