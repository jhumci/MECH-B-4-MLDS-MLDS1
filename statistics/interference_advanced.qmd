# Tests {#sec-statistics-interference_advanced}

Nach dem zuvor beschriebenen Prinzip der Hypothesentests gibt es verschiedene Tests, die auf unterschiedliche Fragestellungen zugeschnitten sind. In diesem Abschnitt werden einige dieser Tests vorgestellt.

Wir werden uns hier auf einige typische Tests konzentrieren. Es gibt noch viele [weitere Tests](https://statsandr.com/blog/files/overview-statistical-tests-statsandr.pdf), die auf spezielle Fragestellungen zugeschnitten sind. Die hier vorgestellten Tests gehören jedoch zu den wichtigsten und werden in der Praxis häufig verwendet.

## T-Test

Der t-Test ist eine Klasse von statistischen Tests, die verwendet werden, um Hypothesen über den Mittelwert (oder die Differenz von Mittelwerten) einer oder zweier Stichproben zu prüfen, insbesondere wenn die Standardabweichung der Grundgesamtheit unbekannt ist und aus der Stichprobe geschätzt werden muss.

### One-Sample Student's T-Test (Einstichproben-t-Test)

Beim Einstichproben-t-Test wird **der** Mittelwert einer Stichprobe mit einem vorgegebenen, hypothetischen Wert ($\mu_0$) verglichen. Der Test wird typischerweise verwendet, wenn die Varianz der Grundgesamtheit unbekannt ist und aus der Stichprobe geschätzt wird. Die t-Verteilung berücksichtigt die zusätzliche Unsicherheit, die durch diese Schätzung entsteht.

Wir legen zunächst den **Typ-I-Fehler** (Signifikanzniveau $\alpha$) fest. Damit definieren wir die maximale Wahrscheinlichkeit, die wir zu akzeptieren bereit sind, die Nullhypothese ($H_0$) fälschlicherweise abzulehnen, obwohl sie wahr ist ($P(\text{Ablehnung } H_0 | H_0 \text{ ist wahr}) \leq \alpha$).

Um zu beurteilen, wie wahrscheinlich die beobachtete Stichprobe unter der Annahme ist, dass die Nullhypothese wahr ist, wird die Teststatistik $t$ berechnet. Diese misst den Unterschied zwischen dem Stichprobenmittelwert $\bar{x}$ und dem hypothetischen Wert $\mu_0$ in Einheiten des Standardfehlers des Mittelwerts. Wörtlich bedeutet die Teststatistik: Um wie viele Standardfehler weicht der Stichprobenmittelwert $\bar{x}$ vom vorgegebenen Wert $\mu_0$ ab?

$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}},
$$

wobei $\bar{x}$ der Stichprobenmittelwert, $s$ die Stichprobenstandardabweichung (oft wird die korrigierte Stichprobenstandardabweichung verwendet) und $n$ die Stichprobengröße ist.

Unter der Annahme, dass die Nullhypothese wahr ist und die Daten aus einer normalverteilten Grundgesamtheit stammen, folgt die Teststatistik $t$ einer t-Verteilung mit $n-1$ Freiheitsgraden.

Die Entscheidung über die Ablehnung der Nullhypothese hängt von der Alternativhypothese ($H_1$) ab:

* Bei $H_1: \mu > \mu_0$ (rechtseitiger Test) lehnen wir $H_0$ ab, wenn $t > t_{1-\alpha, n-1}$.
* Bei $H_1: \mu < \mu_0$ (linksseitiger Test) lehnen wir $H_0$ ab, wenn $t < t_{\alpha, n-1}$ (was $t < -t_{1-\alpha, n-1}$ entspricht).
* Bei $H_1: \mu \neq \mu_0$ (zweiseitiger Test) lehnen wir $H_0$ ab, wenn $|t| > t_{1-\alpha/2, n-1}$.

Der kritische Wert $t_{\text{krit}}$ (z.B. $t_{1-\alpha, n-1}$ oder $t_{1-\alpha/2, n-1}$) wird aus der [Tabelle der t-Verteilung](https://de.wikipedia.org/wiki/Studentsche_t-Verteilung) oder mittels Software bestimmt.

### Beispiel: Eiweißgehalt von Braugerste {#sec-statistics-t-test-barley}

Eine Brauerei bezieht eine neue Charge Gerste. Für den Brauprozess ist es wichtig, dass der mittlere Eiweißgehalt der Gerste einen bestimmten Grenzwert nicht überschreitet, da ein zu hoher Eiweißgehalt zu unerwünscht starkem Schäumen des Bieres führen kann. Der maximal akzeptable mittlere Eiweißgehalt liegt laut Spezifikation bei $\mu_0 = 11.5\%$.

Die Brauerei möchte prüfen, ob die neue Charge Gerste diese Spezifikation einhält oder ob der mittlere Eiweißgehalt signifikant höher ist. Dazu wird eine Stichprobe von $n=50$ Körnern aus der Charge entnommen und deren Eiweißgehalt analysiert.

```{python}
#| classes: styled-output
#| fig-cap: "Verteilung des Eiweißgehalts in der Stichprobe und der maximal zulässige Mittelwert (Nullhypothese)."
#| label: fig-sec-statistics-hypothesistests-barley
#| echo: true

import numpy as np
from scipy.stats import t as t_dist, norm
import matplotlib.pyplot as plt
import seaborn as sns

# Annahmen für die Simulation (wären in der Realität unbekannt)
# Nehmen wir an, die Charge ist tatsächlich leicht über dem Limit
true_mu_barley = 11.8  # Tatsächlicher mittlerer Eiweißgehalt der Charge (%)
true_sigma_barley = 0.5 # Tatsächliche Standardabweichung des Eiweißgehalts (%)

# Nullhypothese (Grenzwert)
mu_0_barley = 11.5

# Stichprobe ziehen
n_barley = 50
# Setze einen Seed für Reproduzierbarkeit
np.random.seed(2024)
X_barley = np.random.normal(true_mu_barley, true_sigma_barley, n_barley)

# Schätzer aus der Stichprobe berechnen
x_bar_barley = np.mean(X_barley)
s_barley = np.std(X_barley, ddof=1) # Korrigierte Stichprobenstandardabweichung

print(f"Stichprobenmittelwert (x̄): {x_bar_barley:.2f}%")
print(f"Stichprobenstandardabweichung (s): {s_barley:.2f}%")
print(f"Stichprobengröße (n): {n_barley}")

# Plot der Stichprobendaten und der Nullhypothese
plt.figure(figsize=(10, 6))
sns.histplot(X_barley, bins=8, kde=False, alpha=0.6, label='Stichprobe Eiweißgehalt', color='darkorange', edgecolor='black')
plt.axvline(mu_0_barley, color='red', linestyle='--', linewidth=2, label=f'Grenzwert H₀: μ ≤ {mu_0_barley}%')
plt.axvline(x_bar_barley, color='blue', linestyle='-', linewidth=2, label=f'Stichprobenmittelwert x̄ = {x_bar_barley:.2f}%')
plt.title('Verteilung des Eiweißgehalts der Gerstenprobe und Grenzwert')
plt.xlabel('Eiweißgehalt (%)')
plt.ylabel('Häufigkeit')
plt.legend()
plt.grid(axis='y', alpha=0.5)
plt.show()
```

**Durchführung des Hypothesentests:**

1.  **Definition der Hypothesen:**
    * $H_0: \mu \leq 11.5\%$ (Der mittlere Eiweißgehalt der Charge liegt bei oder unter dem Grenzwert). Wir verwenden für die Berechnung den Grenzfall $H_0: \mu = 11.5\%$.
    * $H_1: \mu > 11.5\%$ (Der mittlere Eiweißgehalt der Charge ist höher als der Grenzwert). Wir wählen einen **einseitigen Test** (rechtsseitig), da uns nur eine Überschreitung des Grenzwerts Sorgen bereitet.

2.  **Definition des Signifikanzniveaus:**
    * Die Brauerei legt $\alpha = 0.05$ fest.
    * Das Risiko, eine Charge fälschlicherweise als *zu eiweißreich* abzulehnen, obwohl sie den Grenzwert einhält ($H_0$ wahr ist), soll maximal 5% betragen.

3.  **Berechnung der Teststatistik $t$:**
    * $t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}$

    ```{python}
    #| echo: true
    # Berechnung der Teststatistik für Gerste
    standard_error_barley = s_barley / np.sqrt(n_barley)
    t_statistic_barley = (x_bar_barley - mu_0_barley) / standard_error_barley
    print(f'Standardfehler (s/√n): {standard_error_barley:.4f}')
    print(f'Teststatistik (t): {t_statistic_barley:.3f}')
    ```
    * Der berechnete Wert ist $t \approx 4.011$.

4.  **Bestimmung des kritischen Wertes $t_{\text{krit}}$:**
    * Wir führen einen einseitigen Test (rechtsseitig) mit $\alpha = 0.05$ und $n-1 = 50-1 = 49$ Freiheitsgraden durch. Wir suchen den Wert $t_{1-\alpha, n-1} = t_{0.95, 49}$.
    * Aus der t-Verteilungstabelle oder mit Software erhalten wir $t_{\text{krit}} \approx 1.677$.

    ```{python}
    #| echo: true
    from scipy.stats import t as t_dist

    alpha_barley = 0.05
    df_barley = n_barley - 1 # Freiheitsgrade
    t_critical_barley = t_dist.ppf(1 - alpha_barley, df_barley)
    print(f'Freiheitsgrade (df): {df_barley}')
    print(f'Kritischer Wert (t_krit) für α={alpha_barley} (einseitig): {t_critical_barley:.3f}')
    ```

    Die Visualisierung der t-Verteilung mit dem Ablehnungsbereich hilft, die Entscheidung zu verstehen:

    ```{python}
    #| classes: styled-output
    #| fig-cap: "t-Verteilung mit 49 Freiheitsgraden und Ablehnungsbereich für den einseitigen Gerstentest (α=0.05)."
    #| label: fig-sec-statistics-hypothesistests-t-distribution-barley
    #| echo: true

    x_t_barley = np.linspace(t_dist.ppf(0.0001, df_barley), t_dist.ppf(0.9999, df_barley), 500)
    y_t_barley = t_dist.pdf(x_t_barley, df_barley)

    plt.figure(figsize=(10, 6))
    plt.plot(x_t_barley, y_t_barley, label=f't-Verteilung (df={df_barley})')
    plt.fill_between(x_t_barley, 0, y_t_barley, where=(x_t_barley > t_critical_barley), color='red', alpha=0.5, label=f'Ablehnungsbereich (α={alpha_barley})')
    plt.axvline(t_statistic_barley, color='black', linestyle='--', label=f'Teststatistik t = {t_statistic_barley:.3f}')
    plt.title('t-Verteilung, kritischer Wert und Teststatistik (Gersten-Eiweißgehalt)')
    plt.xlabel('t-Wert')
    plt.ylabel('Dichte')
    plt.legend()
    plt.grid(alpha=0.5)
    plt.show()
    ```

    ::: {.callout-note}
    **Zur Erinnerung: Die t-Verteilung beim Testen**

    Die t-Verteilung beschreibt, wie sich die Teststatistik $T = \frac{\bar{X} - \mu_0}{S / \sqrt{n}}$ verteilen würde, wenn die Nullhypothese ($H_0: \mu = \mu_0$) wahr wäre und die Daten aus einer normalverteilten Grundgesamtheit stammen. Wir vergleichen unseren aus der Stichprobe berechneten Wert $t$ mit dieser theoretischen Verteilung, um zu sehen, ob er ein plausibler Wert unter $H_0$ ist oder eher ein extremer, unwahrscheinlicher Wert, der gegen $H_0$ spricht.
    :::

5.  **Entscheidung:**
    * Wir vergleichen die Teststatistik $t$ mit dem kritischen Wert $t_{\text{krit}}$. Regel: Lehne $H_0$ ab, wenn $t > t_{\text{krit}}$.
    * Da $t \approx 4.011 > 1.677 \approx t_{\text{krit}}$, lehnen wir die Nullhypothese $H_0$ ab.
    * **Interpretation:** Das Ergebnis ist statistisch signifikant auf dem 5%-Niveau. Es gibt ausreichende Evidenz aus der Stichprobe, um zu schlussfolgern, dass der mittlere Eiweißgehalt dieser Gerstencharge signifikant über dem Grenzwert von 11.5% liegt. Die Brauerei sollte diese Charge möglicherweise nicht verwenden oder entsprechend behandeln, um Probleme mit dem Schaum zu vermeiden.

    * **p-Wert:** Berechnung der Wahrscheinlichkeit, unter $H_0$ eine Teststatistik zu beobachten, die mindestens so extrem ist wie $t \approx 4.011$.
  ```{python}
  #| echo: true
  p_value_barley = 1 - t_dist.cdf(t_statistic_barley, df_barley)
  print(f'p-Wert: {p_value_barley:.3e}') # Formatierung in wissenschaftlicher Notation
  # Vergleich mit alpha
  if p_value_barley < alpha_barley:
      print(f"Da p-Wert ({p_value_barley:.3e}) < α ({alpha_barley}), wird H₀ abgelehnt.")
  else:
      print(f"Da p-Wert ({p_value_barley:.3e}) >= α ({alpha_barley}), wird H₀ nicht abgelehnt.")
  ```
    * Der p-Wert ist sehr klein ($p \approx 9.98 \times 10^{-5}$). Das bedeutet, es ist extrem unwahrscheinlich, einen Stichprobenmittelwert wie den beobachteten (oder einen noch höheren) zu erhalten, wenn der wahre mittlere Eiweißgehalt der Charge tatsächlich nur 11.5% (oder weniger) wäre. Da $p < \alpha$, wird $H_0$ abgelehnt.

::: {.callout-important}
**Konsequenz der Testentscheidung**

In diesem Beispiel führt die Ablehnung der Nullhypothese zu der Schlussfolgerung, dass der Eiweißgehalt wahrscheinlich zu hoch ist. Dies hat praktische Konsequenzen für die Brauerei (z.B. Ablehnung der Charge, Anpassung des Brauprozesses). Wäre die Nullhypothese nicht abgelehnt worden ($t \leq t_{krit}$ oder $p > \alpha$), hätte die Brauerei keinen statistischen Grund gehabt, die Charge aufgrund des Eiweißgehalts abzulehnen (basierend auf dieser Stichprobe und dem gewählten Signifikanzniveau).
:::


::: {.callout-important}
**Der p-Wert**

Der **p-Wert** ist die Wahrscheinlichkeit, unter Annahme der Gültigkeit der Nullhypothese ($H_0$), ein Ergebnis zu erhalten, das mindestens so extrem ist wie das in der Stichprobe beobachtete Ergebnis (repräsentiert durch die Teststatistik).

* Ein kleiner p-Wert (typischerweise $p \leq \alpha$) deutet darauf hin, dass das beobachtete Ergebnis unter $H_0$ sehr unwahrscheinlich ist. Dies liefert Evidenz *gegen* $H_0$ und führt zur Ablehnung von $H_0$.
* Ein großer p-Wert ($p > \alpha$) bedeutet, dass das beobachtete Ergebnis unter $H_0$ durchaus plausibel ist. Es gibt keine ausreichende Evidenz, um $H_0$ abzulehnen.

Der p-Wert ist **nicht** die Wahrscheinlichkeit, dass $H_0$ wahr ist.
:::

### Aufgabe: Eiweißgehalt von Braugerste {#sec-statistics-t-test-barley-Two}

Eine Brauerei prüft, ob der Eiweißgehalt einer neuen Gerstencharge im optimalen Bereich von 10.5% liegt. Ein zu hoher oder zu niedriger Eiweißgehalt kann die Bierqualität beeinträchtigen. Führen Sie einen **zweiseitigen t-Test** durch, um zu testen, ob der mittlere Eiweißgehalt der Charge signifikant von 10.5% abweicht. Verwenden Sie eine Stichprobe von $n=50$ Körnern mit den folgenden Daten:

- Stichprobenmittelwert: $\bar{x} = 10.47\%$
- Stichprobenstandardabweichung: $s = 0.49\%$
- Signifikanzniveau: $\alpha = 0.05$

**Hypothesen:**

- $H_0: \mu = 10.5\%$ (Der Eiweißgehalt entspricht dem Zielwert).
- $H_1: \mu \neq 10.5\%$ (Der Eiweißgehalt weicht ab).

**Entscheidungsregel:**

- Zweiseitig: $H_0$ wird abgelehnt, wenn $|t| > t_{1-\alpha/2, n-1}$.
- Kritischer Wert $t_{\text{krit}}$ aus einer [t-Verteilungstabelle](https://de.wikipedia.org/wiki/Studentsche_t-Verteilung) oder Software.

Berechnen Sie die Teststatistik $t$, den kritischen Wert $t_{\text{krit}}$ und den p-Wert. Entscheiden Sie, ob $H_0$ abgelehnt wird, und interpretieren Sie das Ergebnis.

::: {.callout-caution collapse="true" title="Musterlösung"}
## Musterlösung

**Schritt 1: Gegebene Werte**
- $\bar{x} = 10.47\%$, $s = 0.49\%$, $n = 50$, $\mu_0 = 10.5\%$, $\alpha = 0.05$.

**Schritt 2: Teststatistik berechnen**
Die Formel für die Teststatistik ist:

$$
t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}
$$

Standardfehler: $s / \sqrt{n} = 0.49 / \sqrt{50} \approx 0.0693$

Teststatistik:

$$
t = \frac{10.47 - 10.5}{0.0693} \approx -0.433
$$

```{python}
#| echo: true
import numpy as np
x_bar = 10.47
s = 0.49
n = 50
mu_0 = 10.5
standard_error = s / np.sqrt(n)
t_statistic = (x_bar - mu_0) / standard_error
print(f"Standardfehler: {standard_error:.4f}")
print(f"Teststatistik t: {t_statistic:.3f}")
```

**Schritt 3: Kritischer Wert**

Freiheitsgrade: $df = n - 1 = 49$. Für einen zweiseitigen Test mit $\alpha = 0.05$ ist der kritische Wert $t_{1-\alpha/2, 49} = t_{0.975, 49} \approx 2.010$ (aus t-Tabelle oder Software).

```{python}
#| echo: true
from scipy.stats import t as t_dist
alpha = 0.05
df = n - 1
t_critical = t_dist.ppf(1 - alpha/2, df)
print(f"Kritischer Wert t_krit: ±{t_critical:.3f}")
```

**Schritt 4: p-Wert**

Der p-Wert für einen zweiseitigen Test ist: $p = 2 \cdot P(T \geq |t|)$.

```{python}
#| echo: true
p_value = 2 * (1 - t_dist.cdf(abs(t_statistic), df))
print(f"p-Wert: {p_value:.3f}")
```

Ergebnis: $p \approx 0.667$.

**Schritt 5: Entscheidung**

- Vergleich: $|t| \approx 0.433 < 2.010 \approx t_{\text{krit}}$, daher wird $H_0$ nicht abgelehnt.
- Alternativ: $p \approx 0.667 > 0.05$, bestätigt die Nicht-Ablehnung.

**Interpretation**

Es gibt keinen statistischen Hinweis, dass der Eiweißgehalt der Gerstencharge signifikant von 10.5% abweicht. Die Charge liegt im optimalen Bereich, und die Brauerei kann sie verwenden, ohne Anpassungen vornehmen zu müssen.
:::


## Zwei-Stichproben-t-Test (Independent Samples t-Test)

Häufig ist man daran interessiert, ob sich die Mittelwerte zweier **unabhängiger** Stichproben signifikant voneinander unterscheiden. Zum Beispiel könnten wir vergleichen, ob sich die mittlere Zugfestigkeit von Stählen zweier verschiedener Lieferanten unterscheidet. Auch hierfür kann ein t-Test eingesetzt werden (vgl. Abb. @fig-sec-statistics-hypothesistests-two-sample-t-test).

![Grundidee des Zwei-Stichproben-t-Tests: Vergleich der Mittelwerte zweier Verteilungen. Quelle: @Inductiveload_TwoSampleTTest](https://upload.wikimedia.org/wikipedia/commons/3/35/Two_sample_ttest.svg){#fig-sec-statistics-hypothesistests-two-sample-t-test}

**Voraussetzungen:**

1.  Die beiden Stichproben sind **unabhängig** voneinander.
2.  Die Daten in beiden Stichproben stammen aus **normalverteilten** Grundgesamtheiten. (Der Test ist robust gegenüber Verletzungen dieser Annahme bei ausreichender Stichprobengröße, ca. n > 30 pro Gruppe).
3.  Die **Varianzen** der beiden Grundgesamtheiten sind **gleich** ($\sigma_1^2 = \sigma_2^2$). Diese Annahme kann mit Tests wie dem Levene-Test überprüft werden. Wenn die Varianzen ungleich sind, wird eine Variante des t-Tests namens Welch-Test verwendet, der die Freiheitsgrade anpasst.

**Hypothesen (Standardfall: Test auf Gleichheit der Mittelwerte):**

* $H_0: \mu_1 = \mu_2$ (oder äquivalent $H_0: \mu_1 - \mu_2 = 0$)
* $H_1: \mu_1 \neq \mu_2$ (zweiseitig), oder $H_1: \mu_1 > \mu_2$ (rechtsseitig), oder $H_1: \mu_1 < \mu_2$ (linksseitig)

**Teststatistik (bei gleichen Varianzen):**

1.  Berechne die **gepoolte (kombinierte) Varianz** $s_p^2$ als gewichteten Durchschnitt der beiden Stichprobenvarianzen:
    $$
    s_p^2 = \frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}
    $$
    wobei $n_1, n_2$ die Stichprobengrößen und $s_1^2, s_2^2$ die (korrigierten) Stichprobenvarianzen sind. $s_p = \sqrt{s_p^2}$ ist die gepoolte Standardabweichung.

2.  Berechne die **Teststatistik $t$**:
    $$
    t = \frac{(\bar{x}_1 - \bar{x}_2) - (\mu_1 - \mu_2)_0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
    $$
    Für den Standardtest auf Gleichheit ist $(\mu_1 - \mu_2)_0 = 0$, also vereinfacht sich die Formel zu:
    $$
    t = \frac{\bar{x}_1 - \bar{x}_2}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
    $$

**Freiheitsgrade und Entscheidung:**

* Die Teststatistik folgt unter $H_0$ einer t-Verteilung mit $df = n_1 + n_2 - 2$ Freiheitsgraden.
* Bestimme den kritischen Wert $t_{\text{krit}}$ basierend auf $\alpha$, den Freiheitsgraden $df$ und der Alternativhypothese (ein- oder zweiseitig, z.B. $t_{1-\alpha/2, df}$ für zweiseitig).
* Vergleiche $t$ mit $t_{\text{krit}}$. Bei einem zweiseitigen Test: Lehne $H_0$ ab, wenn $|t| > t_{\text{krit}}$.
* Alternativ: Berechne den p-Wert und vergleiche ihn mit $\alpha$. Lehne $H_0$ ab, wenn $p \leq \alpha$.

::: {.callout-note}
**Test auf eine spezifische Differenz der Erwartungswerte**

Statt auf Gleichheit der Mittelwerte ($\mu_1 - \mu_2 = 0$) zu testen, könnte man auch prüfen, ob sich die Mittelwerte um einen bestimmten Betrag $\omega_0$ unterscheiden. Die Nullhypothese wäre dann $H_0: \mu_1 - \mu_2 = \omega_0$. Die Teststatistik $t$ wird dann wie folgt berechnet:
$$
t = \frac{(\bar{x}_1 - \bar{x}_2) - \omega_0}{s_p \sqrt{\frac{1}{n_1} + \frac{1}{n_2}}}
$$
Die Freiheitsgrade der t-Verteilung bleiben $n_1 + n_2 - 2$ (bei Varianzgleichheit).
:::

::: {.callout-note}
**Test bei gepaarten Stichproben (Paired Samples t-Test)**

In manchen Fällen sind die beiden Stichproben **nicht unabhängig**, sondern **gepaart**. Das klassische Beispiel ist eine Messung *vor* und *nach* einer Behandlung an denselben Untersuchungseinheiten (z.B. Patienten, Bauteilen). Hier interessiert uns nicht der Unterschied der Mittelwerte unabhängiger Gruppen, sondern der mittlere Unterschied *innerhalb* der Paare.

Beispiel: Ein Verfahren zum Härten eines metallischen Bauteils soll untersucht werden. Im Experiment wird der Härtegrad von $n=10$ Bauteilen jeweils *vor* und *nach* der Behandlung gemessen.

Tabelle: Härtegrad in HR (Rockwell) vor und nach der Behandlung

| Bauteil | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   |
| :------ | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| Vorher  | 49.1 | 49.2 | 49.3 | 49.4 | 49.5 | 49.6 | 49.7 | 49.8 | 49.0 | 50.0 |
| Nachher | 50.2 | 50.3 | 50.3 | 50.2 | 50.7 | 50.7 | 50.8 | 50.9 | 51.0 | 51.1 |
| Differenz (Nachher - Vorher) | 1.1  | 1.1  | 1.0  | 0.8  | 1.2  | 1.1  | 1.1  | 1.1  | 2.0  | 1.1  |

**Vorgehen:**

1.  Berechne die **Differenzen** $d_i = \text{Wert}_{\text{nachher}, i} - \text{Wert}_{\text{vorher}, i}$ für jedes Paar $i$.
2.  Behandle diese Differenzen $d_1, d_2, ..., d_n$ als **eine einzelne Stichprobe**.
3.  Führe einen **Einstichproben-t-Test** für diese Differenzen durch, um zu prüfen, ob der mittlere Unterschied $\mu_d$ signifikant von einem bestimmten Wert (meistens 0) abweicht.

**Hypothesen (Test auf signifikante Erhöhung):**

* $H_0: \mu_d = 0$ (Die Behandlung hat im Mittel keinen Effekt auf die Härte.)
* $H_1: \mu_d > 0$ (Die Behandlung erhöht im Mittel den Härtegrad.)

**Berechnungen:**

* Berechne den Mittelwert der Differenzen $\bar{d}$ und die Standardabweichung der Differenzen $s_d$.

```{python}
#| classes: styled-output
#| echo: true
import numpy as np
from scipy.stats import t as t_dist

vorher = np.array([49.1, 49.2, 49.3, 49.4, 49.5, 49.6, 49.7, 49.8, 49.0, 50.0])
nachher = np.array([50.2, 50.3, 50.3, 50.2, 50.7, 50.7, 50.8, 50.9, 51.0, 51.1])
d = nachher - vorher
print("Differenzen (d):", d)

d_bar = np.mean(d)
s_d = np.std(d, ddof=1) # Korrigierte Standardabweichung
n = len(d)
print(f'Mittlere Differenz (d̄): {d_bar:.3f}')
print(f'Standardabweichung der Differenzen (s_d): {s_d:.3f}')
print(f'Anzahl Paare (n): {n}')

# Teststatistik berechnen (H0: mu_d = 0)
mu_d0 = 0
t_stat_paired = (d_bar - mu_d0) / (s_d / np.sqrt(n))
print(f'Teststatistik (t): {t_stat_paired:.3f}')
```

* Der mittlere Unterschied beträgt $\bar{d} \approx 1.16$ und die Standardabweichung $s_d \approx 0.317$. Die Teststatistik ist $t \approx 11.58$.

**Testdurchführung:**

1.  **Voraussetzungen:** Die *Differenzen* sollten annähernd normalverteilt sein (oder $n$ groß genug). Die Messungen sind gepaart.
2.  **Hypothesen:** $H_0: \mu_d = 0$, $H_1: \mu_d > 0$.
3.  **Signifikanzniveau:** $\alpha = 0.05$.
4.  **Teststatistik:** $t = \frac{\bar{d} - 0}{s_d / \sqrt{n}} \approx 11.58$.
5.  **Kritischer Wert:** Für einen einseitigen Test mit $\alpha = 0.05$ und $df = n-1 = 10-1 = 9$ Freiheitsgraden ist $t_{\text{krit}} = t_{0.95, 9}$.

    ```{python}
    #| classes: styled-output
    #| echo: true
    df_paired = n - 1
    alpha_paired = 0.05
    t_crit_paired = t_dist.ppf(1 - alpha_paired, df_paired)
    print(f'Freiheitsgrade (df): {df_paired}')
    print(f'Kritischer Wert (t_krit) für α={alpha_paired} (einseitig): {t_crit_paired:.3f}')
    ```
    Der kritische Wert ist $t_{\text{krit}} \approx 1.833$.

6.  **Entscheidung:** Da $t \approx 11.58 > 1.833 \approx t_{\text{krit}}$, lehnen wir $H_0$ ab.
    * **Interpretation:** Es gibt starke statistische Evidenz dafür, dass die Behandlung den Härtegrad der Bauteile signifikant erhöht.
    * **p-Wert:**
    
```{python}
#| echo: true
p_value_paired = 1 - t_dist.cdf(t_stat_paired, df_paired)
print(f'p-Wert (einseitig): {p_value_paired:.3e}')
if p_value_paired < alpha_paired:
    print(f"Da p-Wert ({p_value_paired:.3e}) < α ({alpha_paired}), wird H₀ abgelehnt.")
else:
      print(f"Da p-Wert ({p_value_paired:.3e}) >= α ({alpha_paired}), wird H₀ nicht abgelehnt.")
```

    Der p-Wert ist extrem klein ($p \approx 1.35 \times 10^{-6}$), was die Ablehnung von $H_0$ bestätigt.
:::


## Chi-Quadrat-Test

Der Chi-Quadrat-Test prüft Hypothesen über kategoriale Daten, z. B. ob beobachtete Häufigkeiten mit erwarteten Häufigkeiten übereinstimmen. Ein häufiger Anwendungsfall ist der **Anpassungstest** (Goodness-of-Fit), der testet, ob eine Stichprobe einer bestimmten Verteilung entspricht.

Die Teststatistik misst die Abweichung zwischen beobachteten ($O_i$) und erwarteten ($E_i$) Häufigkeiten:

$$
\chi^2 = \sum \frac{(O_i - E_i)^2}{E_i}
$$

Unter der Nullhypothese ($H_0$) folgt die Statistik einer Chi-Quadrat-Verteilung mit $k-1$ Freiheitsgraden ($k$ = Anzahl Kategorien). Ein großer $\chi^2$-Wert spricht gegen $H_0$.

## Beispiel: Qualität eines Lieferanten

Ein neuer Lieferant (A) liefert Bauteile, die in vier Kategorien eingeteilt werden: „OK“, „Fehler 1“, „Fehler 2“, „Fehler 3“. Wir prüfen, ob die Qualitätsverteilung von Lieferant A mit der bisherigen Verteilung (erwartete Anteile: OK: 81%, Fehler 1: 8%, Fehler 2: 6%, Fehler 3: 5%) übereinstimmt. Stichprobe: $n=120$ Teile.

**Beobachtete Häufigkeiten:**

- OK: 100
- Fehler 1: 10
- Fehler 2: 5
- Fehler 3: 5

**Erwartete Häufigkeiten:**

- OK: $120 \times 0.81 = 97.2$
- Fehler 1: $120 \times 0.08 = 9.6$
- Fehler 2: $120 \times 0.06 = 7.2$
- Fehler 3: $120 \times 0.05 = 6.0$

**Hypothesen:**

- $H_0$: Lieferant A hat die gleiche Qualitätsverteilung wie bisherige Lieferanten.
- $H_1$: Die Verteilung unterscheidet sich.

**Testdurchführung:**

1. **Voraussetzungen:** Erwartete Häufigkeiten $E_i \geq 5$, Stichprobe zufällig.
2. **Signifikanzniveau:** $\alpha = 0.05$.
3. **Teststatistik:**

```{python}
#| echo: true
import numpy as np
from scipy.stats import chi2

O = np.array([100, 10, 5, 5])
E = np.array([97.2, 9.6, 7.2, 6.0])
chi2_statistic = np.sum((O - E)**2 / E)
print(f"Chi-Quadrat Statistik: {chi2_statistic:.3f}")
```

   Ergebnis: $\chi^2 \approx 0.936$.

4. **Kritischer Wert:** 

Für $df = 4-1 = 3$ und $\alpha = 0.05$ ist $\chi^2_{\text{krit}} \approx 7.815$.

5. **Entscheidung:** 

Da $\chi^2 \approx 0.936 < 7.815$, wird $H_0$ nicht abgelehnt.

**Interpretation:** 

Es gibt keinen Hinweis, dass sich die Qualität von Lieferant A signifikant von bisherigen Lieferanten unterscheidet.

```{python}
#| echo: true
p_value = 1 - chi2.cdf(chi2_statistic, 3)
print(f"p-Wert: {p_value:.3f}")
```

**p-Wert:** $p \approx 0.817 > 0.05$, bestätigt die Nicht-Ablehnung von $H_0$.

## Übersicht über Statistische Tests

Grundsätzlich setzen wir statischtische Tests ein, wenn wir eine Hypothese über eine Grundgesamtheit aufstellen und diese Hypothese auf Basis einer Stichprobe überprüfen wollen. Die Hypothese wird in eine Nullhypothese $H_0$ und eine Alternativhypothese $H_1$ aufgeteilt. Die Nullhypothese ist die Hypothese, die wir widerlegen wollen, während die Alternativhypothese die Hypothese ist, die wir annehmen, wenn die Nullhypothese widerlegt wird.

Test ermöglichen und zu unterschieden, ob die durch uns auf Grund der Stichprobe getroffene Aussage auf die Grundgesamtheit übertragbar oder möglicherweise nur Zufall sind.

<!-- Hier Einen Link zu möglichen Fragestellungen und tests einführen -->